{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Naive Bayes for spam filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, we will use the Naive Bayes algorithm to fit a spam filter by hand. This will enhance your\n",
    "understanding to Bayes classifier and build intuition. This question does not involve any programming but\n",
    "only derivation and hand calculation.\n",
    "Spam filters are used in all email services to classify received emails as “Spam” or “Not Spam”. A simple\n",
    "approach involves maintaining a vocabulary of words that commonly occur in “Spam” emails and classifying\n",
    "an email as “Spam” if the number of words from the dictionary that are present in the email is over a certain\n",
    "threshold. We are given the vocabulary consists of 15 words\n",
    "V = {secret, offer, low, price, valued, customer, today, dollar, million, sports, is, for, play, healthy, pizza}.\n",
    "We will use Vi to represent the ith word in V . As our training dataset, we are also given 3 example spam\n",
    "messages,\n",
    "\n",
    "• million dollar offer\n",
    "• secret offer today\n",
    "• secret is secret\n",
    "\n",
    "and 4 example non-spam messages\n",
    "\n",
    "• low price for valued customer\n",
    "• play secret sports today\n",
    "• sports is healthy\n",
    "• low price pizza\n",
    "\n",
    "Recall that the Naive Bayes classifier assumes the probability of an input depends on its input feature.\n",
    "The feature for each sample is defined as x\n",
    "(i) = [x\n",
    "(i)\n",
    "1\n",
    ", x\n",
    "(i)\n",
    "2\n",
    ", . . . , x\n",
    "(i)\n",
    "d\n",
    "]\n",
    "T\n",
    ", i = 1, . . . , m and the class of the ith\n",
    "sample is y\n",
    "(i)\n",
    ". In our case the length of the input vector is d = 15, which is equal to the number of words\n",
    "in the vocabulary V . Each entry x\n",
    "(i)\n",
    "j\n",
    "is equal to the number of times word Vj occurs in the i-th message.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Calculate class prior P(y = 0) and P(y = 1) from the training data, where y = 0 corresponds\n",
    "to spam messages, and y = 1 corresponds to non-spam messages. Note that these class prior essentially\n",
    "corresponds to the frequency of each class in the training sample. Write down the feature vectors for\n",
    "each spam and non-spam messages.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    **Priors:**\n",
    "\n",
    "    P(y=1) = 3/7\n",
    "\n",
    "    P(y=0) = 4/7\n",
    "\n",
    "\n",
    "\n",
    "    **Feature Vectors for messages:**\n",
    "\n",
    "| message# | SPAM?    | secret | offer | low | price | valued | customer | today | dollar | million | sports | is | for | play | healthy | pizza |\n",
    "|----------|----------|--------|-------|-----|-------|--------|----------|-------|--------|---------|--------|----|-----|------|---------|-------|\n",
    "| 1        | not spam | 0      | 0     | 1   | 1     | 1      | 1        | 0     | 0      | 0       | 0      | 0  | 1   | 0    | 0       | 0     |\n",
    "| 2        | not spam | 1      | 0     | 0   | 0     | 0      | 0        | 1     | 0      | 0       | 1      | 0  | 0   | 1    | 0       | 0     |\n",
    "| 3        | not spam | 0      | 0     | 0   | 0     | 0      | 0        | 0     | 0      | 0       | 1      | 1  | 0   | 0    | 1       | 0     |\n",
    "| 4        | not spam | 0      | 0     | 1   | 1     | 0      | 0        | 0     | 0      | 0       | 0      | 0  | 0   | 0    | 0       | 1     |\n",
    "| 5        | spam     | 0      | 1     | 0   | 0     | 0      | 0        | 0     | 1      | 1       | 0      | 0  | 0   | 0    | 0       | 0     |\n",
    "| 6        | spam     | 1      | 1     | 0   | 0     | 0      | 0        | 1     | 0      | 0       | 0      | 0  | 0   | 0    | 0       | 0     |\n",
    "| 7        | spam     | 2      | 0     | 0   | 0     | 0      | 0        | 0     | 0      | 0       | 0      | 1  | 0   | 0    | 0       | 0     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. (In the Naive Bayes model, assuming the keywords are independent of each other (this is a\n",
    "simplification), the likelihood of a sentence with its feature vector x given a class c is given by\n",
    "P(x|y = c) = Y\n",
    "d\n",
    "k=1\n",
    "θ\n",
    "xk\n",
    "c,k, c = {0, 1}\n",
    "where 0 ≤ θc,k ≤ 1 is the probability of word k appearing in class c, which satisfies\n",
    "X\n",
    "d\n",
    "k=1\n",
    "θc,k = 1, c = {0, 1}.\n",
    "Given this, the complete log-likelihood function for our training data is given by\n",
    "(θ0,1, . . . , θ0,d, θ1,1, . . . , θ1,d) = Xm\n",
    "i=1\n",
    "X\n",
    "d\n",
    "k=1\n",
    "x\n",
    "(i)\n",
    "k\n",
    "log θy(i),k\n",
    "(In this example, m = 7.) Calculate the maximum likelihood estimates of θ0,1, θ0,7, θ1,1, θ1,15 by\n",
    "maximizing the log-likelihood function above.\n",
    "(Hint: We are solving a constrained maximization problem and you will need to introduce Lagrangian\n",
    "multipliers and consider the Lagrangian function.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to maximize the following:\n",
    "\n",
    "$$ \\ell(\\theta_{0,1},...,\\theta_{0,d},\\theta_{1,1},...,\\theta_{1.d}) = \\sum^m_{i=1} \\sum^d_{k=1} x^i_k log \\theta_{y^i,k} $$\n",
    "\n",
    "subject to:\n",
    "\n",
    "$$ \\sum^d_{k=1} \\theta_{c,k} = 1  ,  c = {0,1} $$\n",
    "\n",
    "The Lagrangian is thus:\n",
    "\n",
    "$$ L(\\theta_{c,k}, \\lambda_1, \\lambda_2)  = \\sum^m_{i=1} \\sum^d_{k=1} x^i_k log \\theta_{y^i,k} + \\lambda_1(\\sum^d_{k=1} \\theta_{0,k} - 1) + \\lambda_2(\\sum^d_{k=1} \\theta_{1,k} - 1) $$\n",
    "\n",
    "If we then differentiate with respect to $\\theta$ and then set that to zero we get:\n",
    "$$\\theta_{c,k} = \\frac{x^i_k} {\\lambda}$$\n",
    "\n",
    "If we then substitue the above term in the constraints, to that $\\sum^d_{k=1} \\theta_{0,k} - 1 = \\sum^d_{k=1} \\frac{x^i_k}{\\lambda} - 1$, solve for lambda, and then plug back into our above expressions we get:\n",
    "\n",
    "$$\\theta_{c,k} = \\frac{x^i_k} {\\sum^d_{k=1} x^i_k}$$\n",
    "\n",
    "The resulting values for $\\theta_{0,1}, \\theta_{0,7}, \\theta_{1,1}, \\theta_{1,15}, \\theta_{1,11}$ are:\n",
    "\n",
    "| theta      | $\\theta_{0,1}$   | $\\theta_{0,7}$   | $\\theta_{1,1}$    | $\\theta_{1,15}$   | $\\theta_{1,7}$    | $\\theta_{0,11}$  | $\\theta_{1,11}$   |\n",
    "|------------|------------------|------------------|-------------------|-------------------|-------------------|------------------|-------------------|\n",
    "| likelihood | 3/9 = .333       | 1/9 = .1111      | 1/15 = .0666      | 1/15 = .0666      | 1/15 = .0666      | 1/9 = .1111      | 1/15 = .0666      |\n",
    "| prior      | 3/7 = .4285      | 3/7 = .4285      | 4/7 = .5714       | 4/7 = .5714       | 4/7 = .5714       | 3/7 = .4285      | 4/7 = .5714       |\n",
    "| bayes      | .4285*.333=.1428 | .4285*.111=.0476 | .5714*.0666=.0381 | .5714*.0666=.0381 | .5714*.0666=.0381 | .4285*.111=.0476 | .5714*.0666=.0381 |\n",
    "\n",
    "We included $\\theta_{1,11}$,  $\\theta_{0,11}$, and $\\theta_{1,7}$ because we will need that in the next question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Given a test message “today is secret”, using the Naive Bayes classier that you have trained\n",
    "in Part (a)-(b), to calculate the posterior and decide whether it is spam or not spam.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to make 2 calculation here: One as if the message was spam, and one as if the mssage was not spam.\n",
    "\n",
    "Spam = $prior$ * $\\theta_{0,1}$ * $\\theta_{0,7}$ * $\\theta_{0,11}$ \n",
    "\n",
    "$$ = .4285 * .3333 * .1111 * .1111 = .00176 $$\n",
    "\n",
    "Non- Spam = $prior$ * $\\theta_{1,1}$ * $\\theta_{1,7}$ * $\\theta_{1,11}$\n",
    "\n",
    "$$ = .5714 * .0666 * .0666 * .0666 = .00017 $$\n",
    "\n",
    "Because .00176 > .00017, we classify this message as a Spam message."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
